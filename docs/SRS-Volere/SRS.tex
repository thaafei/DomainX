% THIS DOCUMENT IS FOLLOWS THE VOLERE TEMPLATE BY Suzanne Robertson and James Robertson
% ONLY THE SECTION HEADINGS ARE PROVIDED
%
% Initial draft from https://github.com/Dieblich/volere
%
% Risks are removed because they are covered by the Hazard Analysis
\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    bookmarks=true,         % show bookmarks bar?
      colorlinks=true,      % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links (change box color with linkbordercolor)
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}
\usepackage{enumitem}
\newcommand{\lips}{\textit{Insert your content here.}}

\input{../Comments}
\input{../Common}

\begin{document}

\title{Software Requirements Specification for \progname: DomainX} 
\author{\authname}
\date{\today}
	
\maketitle

\pagenumbering{roman}
\begin{table}[hp]
\caption{Revision History} \label{TblRevisionHistory}
\begin{tabularx}{\textwidth}{llX}
\toprule
\textbf{Date} & \textbf{Developer(s)} & \textbf{Change}\\
\midrule
October 6, 2025 & Fei Xie & First Draft of Sections: Cost to Ideas for Solution\\
\bottomrule
\end{tabularx}
\end{table}

~\newpage

\tableofcontents

~\newpage
\section{Purpose of the Project}
\subsection{User Business}
\lips
\subsection{Goals of the Project}
\lips
\section{Stakeholders}
\subsection{Client}
\lips
\subsection{Customer}
\lips
\subsection{Other Stakeholders}
\lips
\subsection{Hands-On Users of the Project}
\lips
\subsection{Personas}
\lips
\subsection{Priorities Assigned to Users}
\lips
\subsection{User Participation}
\lips
\subsection{Maintenance Users and Service Technicians}
\lips

\section{Mandated Constraints}
\subsection{Solution Constraints}
\lips
\subsection{Implementation Environment of the Current System}
\lips
\subsection{Partner or Collaborative Applications}
\lips
\subsection{Off-the-Shelf Software}
\lips
\subsection{Anticipated Workplace Environment}
\lips
\subsection{Schedule Constraints}
\lips
\subsection{Budget Constraints}
\lips
\subsection{Enterprise Constraints}
\lips

\section{Naming Conventions and Terminology}
\subsection{Glossary of All Terms, Including Acronyms, Used by Stakeholders
involved in the Project}
\lips

\section{Relevant Facts And Assumptions}
\subsection{Relevant Facts}
\lips
\subsection{Business Rules}
\lips
\subsection{Assumptions}
\lips

\section{The Scope of the Work}
\subsection{The Current Situation}
\lips
\subsection{The Context of the Work}
\lips
\subsection{Work Partitioning}
\lips
\subsection{Specifying a Business Use Case (BUC)}
\lips

\section{Business Data Model and Data Dictionary}
\subsection{Business Data Model}
\lips
\subsection{Data Dictionary}
\lips

\section{The Scope of the Product}
\subsection{Product Boundary}
\lips
\subsection{Product Use Case Table}
\lips
\subsection{Individual Product Use Cases (PUC's)}
\lips

\section{Functional Requirements}
\subsection{Functional Requirements}
\lips

\section{Look and Feel Requirements}
\subsection{Appearance Requirements}
\lips
\subsection{Style Requirements}
\lips

\section{Usability and Humanity Requirements}
\subsection{Ease of Use Requirements}
\lips
\subsection{Personalization and Internationalization Requirements}
\lips
\subsection{Learning Requirements}
\lips
\subsection{Understandability and Politeness Requirements}
\lips
\subsection{Accessibility Requirements}
\lips

\section{Performance Requirements}
\subsection{Speed and Latency Requirements}
\lips
\subsection{Safety-Critical Requirements}
\lips
\subsection{Precision or Accuracy Requirements}
\lips
\subsection{Robustness or Fault-Tolerance Requirements}
\lips
\subsection{Capacity Requirements}
\lips
\subsection{Scalability or Extensibility Requirements}
\lips
\subsection{Longevity Requirements}
\lips

\section{Operational and Environmental Requirements}
\subsection{Expected Physical Environment}

\begin{enumerate}[label=OE-EPE\arabic*]
\item The tool is a web-based application that will be used mainly by our team, supervisors, and potentially other researchers or domain experts.
\item It is expected to run on a standard desktop or laptop computer with a reliable internet connection, in a normal indoor setting such as an office, lab, or home workspace.
\item No specialized hardware or rugged equipment is required. A keyboard, mouse, or touchpad, and a modern web browser (e.g., Chrome, Firefox, Edge) are sufficient.
\end{enumerate}

\subsection{Wider Environment Requirements}
\begin{enumerate}[label=OE-WE\arabic*]
\item The application depends on a stable internet connection for retrieving data from public repositories (e.g., GitHub) and for loading the hosted web interface if deployed to the cloud.
\item It does not rely on any dedicated on-premises hardware.
\item The tool should work on the latest two to three major versions of common browsers such as Chrome, Firefox, and Edge. No special environmental conditions (lighting, noise, temperature) are expected to affect usability.
\end{enumerate}
\subsection{Requirements for Interfacing with Adjacent Systems}
The tool must be able to communicate with a few external systems and internal components to collect, store, and visualize data.

\begin{enumerate}[label=OE-IA\arabic*]

  \item Public Repository APIs (e.g., GitHub API): The tool must communicate with external repository services to automatically collect information about the selected neural-network libraries. For example, it needs to retrieve details such as how often the code is updated, the number of open or closed issues and pull requests, and the main programming languages used. This data will help evaluate qualities like maintainability, transparency, and overall project activity. The information must be received in a standard machine-readable format (e.g., JSON over HTTPS) whenever a user triggers a scan or during scheduled updates.

  \item Database (MySQL): The backend must store scores, rankings, and evidence collected from repositories.

  \item Visualization Component: The frontend must render charts and comparisons (e.g., using Chart.js) from the data served by the backend.

  \item All connections must use standard web technologies (HTTP/HTTPS, JSON) and require only basic authentication methods such as API tokens for secure access to external repository APIs.

\end{enumerate}

\subsection{Productization Requirements}
The tool will be delivered as an open-source web application hosted in the team’s public GitHub repository.
\begin{enumerate}[label=OE-PR\arabic*]
\item A clear README file must explain how to set up the backend (Python + Flask) and the frontend (React) using common package managers such as pip and npm.
\item For developers running the tool locally, the repository must include a requirements.txt file for Python packages and a database schema file so they can create the required tables.
\item When deployed on a cloud platform such as AWS or Google Cloud, users must be able to access the tool directly through a web URL without installing anything.
\item The application must also provide options to export results in formats such as CSV for data tables and PNG/PDF for visualizations.
\end{enumerate}
\subsection{Release Requirements}
\begin{enumerate}[label=OE-RR\arabic*]
\item The project should follow the official capstone timeline: an internal test release before the Proof-of-Concept (PoC) demonstration in \textbf{November}, a Revision~0 Demonstration in \textbf{Weeks~18--19}, and the Final Release (Revision~1) at \textbf{Week~26} along with the research paper and final dataset.
\item The Final Release (Revision 1) must incorporate feedback collected during the Revision 0 Demonstration, including usability improvements, bug fixes, and supervisor/TA-requested changes.
\item All releases must be published as GitHub Releases and include a short changelog describing the changes in each version.

  \item Releases must use a clear, descriptive version tag such as the \texttt{MAJOR.MINOR.PATCH} format (or an equally descriptive format):
    \begin{itemize}
        \item \textbf{MAJOR:} Increased only when a change breaks backward compatibility (e.g., a database schema change that makes older data unusable).
        \item \textbf{MINOR:} Increased when adding new features that remain fully compatible with previous versions.
        \item \textbf{PATCH:} Increased for bug fixes or small improvements that do not affect existing features.
    \end{itemize}

  Example version tags:
    \begin{itemize}
        \item \texttt{v0.1.0} → first working prototype for the Revision~0 Demonstration
        \item \texttt{v0.2.0} → adds a new feature such as exporting the table to a CSV file
        \item \texttt{v0.2.1} → fixes a small bug in the export feature (patch)
        \item \texttt{v1.0.0} → stable Final Release for Revision~1
    \end{itemize}
\end{enumerate}
\section{Maintainability and Support Requirements}
\subsection{Maintenance Requirements}
The tool is an open-source web application that will need occasional updates to fix bugs and to adapt if external APIs change.
\begin{enumerate}[label=MS-MR\arabic*]
\item All code must follow the project’s coding standards (PEP 8 for the Python backend; React + TypeScript style guide for the frontend).
\item Automated tools (such as Black, Flake8, and Pylint) must remain part of the workflow so new contributors can easily read and update the code.
\item Unit tests must be written for all new features and bug fixes. Developers should also run basic integration tests to make sure the full pipeline (API → database → visualization) still works after changes.
\item Test coverage must be tracked and reported to ensure that critical parts of the backend are being tested.
\item All Python and frontend packages must be listed in requirements.txt and package.json, with pinned versions so the same build can be reproduced.
\item The dependency list must be reviewed and updated at least once each semester to keep it current and secure.
\item Any changes to the dataset made through the interactive data table must be logged with a timestamp and the username so there is always a clear audit trail.
\item Most routine fixes, such as small UI tweaks or bug fixes, should be finished within a couple of days. Larger updates, such as adding a new metric or a new visualization, are expected to take about one to two weeks.
\end{enumerate}
\subsection{Supportability Requirements}
The tool is intended to be mostly self-supporting since it will be used primarily by our team, the supervisors, and potentially other researchers in the future.
\begin{enumerate}[label=MS-SR\arabic*]
\item The README file must include step-by-step instructions so that a new developer can set up the backend (Flask + MySQL) and frontend (React) locally, or deploy it to a cloud platform (such as AWS or Google Cloud), in a consistent and repeatable way. A new developer should be able to follow these instructions and have the application running within about two hours.
\item The repository must always include an up-to-date guide for installation, setup, the data-collection workflow, using the interactive data table, visualization, and exporting results.
\item The backend must include logging to record API failures (such as rate-limit errors or unexpected data formats), database issues, and runtime exceptions so that maintainers can troubleshoot problems quickly.
\item Users should use the GitHub Issues page to report bugs or ask questions. No printed manual will be needed; all documentation will remain online in the repository.
\end{enumerate}
\subsection{Adaptability Requirements}
\begin{enumerate}[label=MS-AR\arabic*]
\item The tool must remain flexible so it can grow with the project and adapt to future needs.
\item The MySQL database must be set up so that if a new quality criterion needs to be tracked, it can be added by creating a new column, updating the data-collection script, and adjusting the UI without having to redesign the whole system.
\item The data-collection module must allow new data sources (for example, another code-hosting site or a different metrics service) to be added with minimal extra code and without disrupting the existing GitHub integration.
\item The tool must be able to run on standard operating systems(Windows, macOS, and Linux) by using widely supported technologies (such as Python, Node.js, and MySQL), and by avoiding any system-specific code.
\item The system must be designed in a modular way so that parts like data collection, storage, and visualization remain separate. This makes it easier to add new features or update one part without affecting the rest of the tool.
\end{enumerate}
\section{Security Requirements}
\subsection{Access Requirements}


\begin{enumerate}[label=SR-AC\arabic*]

  \item The tool must be open for anyone to view results, but only approved team members or domain experts may modify the data.

  \item The system must support two user roles:
    \begin{itemize}
        \item \textbf{Viewer:} Can view all interactive data tables that list the libraries, their scores, and rankings, along with all visualizations.
        \item \textbf{Contributor:} Has all Viewer permissions plus the ability to edit data in the interactive table.
    \end{itemize}

  \item Editing or any other administrative actions must be available only to logged-in users with the \textbf{Contributor} role.

  \item User roles (Viewer / Contributor) must be assigned and updated correctly at signup or by an admin so that permissions always reflect the intended access level.

  \item The system must display clear error messages for login failures (e.g., invalid credentials, network errors) and provide a secure way for users to recover or reset their account credentials.

  \item API credentials such as keys or tokens for external services (e.g., repository APIs) must be stored securely outside the source code (e.g., in environment variables) and must never be exposed in the frontend or version control.

\end{enumerate}

\subsection{Integrity Requirements}
\begin{enumerate}[label=SR-INT\arabic*]
\item To ensure the accuracy and reliability of the collected data, all manually entered information into the interactive table must be checked before it is saved. For example, numbers must fall within valid ranges, and text must be cleaned so that it cannot be treated as code or scripts.
\item The database must include safeguards so that if two users edit the same record at the same time, no changes are lost or overwritten.
\item The system must detect simultaneous edits and either block one save or notify the users to resolve the conflict.
\item When automated data updates conflict with a user’s manual edits (if any are updated automatically), the system must warn the user or request confirmation before replacing existing data.
\item The system must also store the raw evidence, calculated scores, and final rankings in separate fields so that the original data and results cannot be accidentally modified.
\item Publishing visualizations must not occur at the same time as data edits or automated refreshes. The system must either block publishing or enforce downtime until updates are complete.
\item If an export (e.g., CSV, PNG) fails or produces a corrupted file, the tool must alert the user and allow them to retry the download.
\end{enumerate}
\subsection{Privacy Requirements}
The tool mainly works with open-source repository data, so there is very little personal data involved.
\begin{enumerate}[label=SR-P\arabic*]
\item If basic user details are collected for login (such as name or email), they must be kept private and stored securely using widely accepted security standards.
\item User passwords must be stored only in hashed form using a secure one-way hashing algorithm so that the actual password is never saved.
\end{enumerate}
No other personal or confidential information will be collected or stored.
\subsection{Audit Requirements}
\begin{enumerate}[label=SR-AU\arabic*]
\item The system must keep a record of all important activity for accountability and troubleshooting. Every time a Contributor adds, edits, or deletes data in the interactive table, the system must save a log entry showing the user’s ID, the time of the action, the type of action, and the fields that were changed.
\item The system must also log key events such as login attempts (successful and failed), scheduled API-collection runs, and major errors so that they can be reviewed later.
\item Access to these logs must be restricted to authorized project admins only.
\end{enumerate}
\subsection{Immunity Requirements}
\begin{enumerate}[label=SR-IM\arabic*]
\item The backend must prevent SQL-injection attacks by using the safe query methods provided by the database library instead of building raw SQL strings with user input.
\item The frontend must display any text entered by users as plain text only and never allow it to run as code. For example, React’s built-in escaping already takes care of this.
\item The automated data-collection scripts must respect the rate limits of external repository APIs (e.g., GitHub). If a limit is reached, the scripts should pause and retry later rather than keep sending requests and risk overloading the service.
\item All Python and React libraries must be kept up to date, so the project does not rely on outdated packages with known security issues. There should also be a tool in place to regularly check for known vulnerabilities in these libraries, such as GitHub Dependabot.
\end{enumerate}

\section{Cultural Requirements}
\subsection{Cultural Requirements}
Since the tool will be shared mostly in an academic and research setting, we just need to make sure the interface stays clear, neutral, and easy to understand for anyone who uses it later.
\begin{enumerate}[label=CU-CR\arabic*]
\item \textbf{Language:} All text in the user interface and documentation must be in plain English. We should avoid using region-specific jargon so that future collaborators from outside McMaster can understand it easily.
\item \textbf{Dates and Numbers:} Dates must be displayed in a clear standard format such as ISO 8601 (YYYY-MM-DD) so they’re unambiguous for anyone who uses the tool. Numbers must use a consistent style (for example, decimal point for fractions and thousands separated by commas).
\item \textbf{Neutral Design:} Colours, labels, and icons must stay neutral and must not include any symbols or words that could carry unintended cultural or political meaning.
\item \textbf{Open-Source Norms:} The repository must include a license notice and simple contribution guidelines to match common open-source practice.
\end{enumerate}
\section{Compliance Requirements}
\subsection{Legal Requirements}
\begin{enumerate}[label=CR-LR\arabic*]
\item The tool must include a copyright notice covering the code and documentation produced by the team.
\item It must be distributed under an appropriate open-source license so that others can reuse it under clearly defined terms.
\item Users of the tool or any data generated by it are required to provide proper citation or acknowledgement when they use it in their own work.
\end{enumerate}
\subsection{Standards Compliance Requirements}
\begin{enumerate}[label=CR-STD\arabic*]
\item N/A
\end{enumerate}
\section{Open Issues}

The following unresolved items could materially affect the design, deployment,
or operation of the NNL Assessment Tool. The issues in
Table~\ref{tab:open-issues} will be tracked until closure to reduce delivery
risk and surprises in later phases.

\begin{table}[hp]
\caption{Open issues to track and resolve} \label{tab:open-issues}
\begin{tabularx}{\textwidth}{p{1.6cm}X X X X p{2.1cm}}
\toprule
\textbf{Issue \#} & \textbf{Summary} & \textbf{Cross-Reference} &
\textbf{Stakeholders} & \textbf{Action Required} & \textbf{Status} \\
\midrule
OI-01 & Finalize hosting environment for the tool (e.g., internal server or
university-managed cloud). & Operational and Environmental Requirements &
CAS Supervisor, Infrastructure Team & Confirm approved infrastructure with IT &
Pending \\
\addlinespace[0.3em]
OI-02 & Confirm the final list of neural network libraries to include in the
tool’s database (based on domain-expert review). & Scope of the Work &
Research Subteam, Domain Expert & Schedule and complete review with domain
expert & Pending \\
\addlinespace[0.3em]
OI-03 & Select user interface (UI) framework and visualization library
(e.g., React with Chart.js vs.\ D3). & Functional Requirements &
Development Team & Evaluate options and record decision & In progress \\
\addlinespace[0.3em]
OI-04 & Decide Excel integration level (import/export only or live
synchronization with spreadsheets). & Functional Requirements & Research
Subteam, Developers & Define use cases and confirm feasibility & Pending \\
\addlinespace[0.3em]
OI-05 & Choose authentication method: McMaster single sign-on (SSO) versus
custom login. & Security Requirements; Operational and Environmental
Requirements & CAS Supervisor, Development Team & Meet with IT to assess SSO
feasibility & Pending \\
\addlinespace[0.3em]
OI-06 & Confirm data storage architecture (e.g., structured query language
(SQL) database versus alternative storage). & Operational and Environmental
Requirements & Developers, Infrastructure Team & Evaluate options and finalize
design & Pending \\
\bottomrule
\end{tabularx}
\end{table}


\section{Off-the-Shelf Solutions}

This section identifies existing tools, software, and components that could be leveraged to reduce development time and cost for the Neural Network Libraries (NNL) Assessment Tool. It outlines reusable libraries and products that can be legally copied or adapted to accelerate development and ensure maintainability.

The goal is to reuse proven, reliable components and avoid reinventing existing functionality, thereby optimizing development effort and leveraging established best practices.

\subsection{Ready-Made Products}

Several existing platforms provide partial functionality aligned with the tool’s goals, particularly in data visualization, analytics, and automation. However, none fully satisfy the requirement for automated data gathering, Analytic Hierarchy Process (AHP) analysis, and integrated visualization.

\begin{table}[hp]
\caption{Ready-Made Products Relevant to the NNL Assessment Tool}
\begin{tabularx}{\textwidth}{p{2.8cm}X X X}
\toprule
\textbf{Product} & \textbf{Description} & \textbf{Relevance to Project} & \textbf{Limitations} \\
\midrule
Microsoft Excel & Spreadsheet with storage, formulas, and charts. & Used as baseline for current manual process. & Lacks automation, scalability, and centralized access. \\
\addlinespace[0.3em]
Google Sheets & Cloud-based collaborative spreadsheet. & Enables multi-user editing and sharing. & Limited automation, manual data import. \\
\addlinespace[0.3em]
Power BI / Tableau & Advanced analytics and visualization tools. & Suitable for dashboards and comparative graphs. & Licensing cost, limited AHP customization. \\
\addlinespace[0.3em]
SurveyMonkey / Google Forms & Online data collection tools. & Useful for gathering expert feedback. & No direct database or analytics integration. \\
\bottomrule
\end{tabularx}
\end{table}

These products may serve as inspiration or integration points (e.g., Excel import/export) but cannot replace the custom automation and analysis required by the NNL Assessment Tool.

\subsection{Reusable Components}

The following open-source libraries and frameworks will be incorporated to support data collection, analysis, and visualization.

\begin{table}[hp]
\caption{Reusable Components}
\begin{tabularx}{\textwidth}{p{2.8cm}X X X}
\toprule
\textbf{Component} & \textbf{Purpose} & \textbf{Source} & \textbf{Justification} \\
\midrule
Python Pandas & Data manipulation and analysis. & Open-source & Handles tabular data and transformations efficiently. \\
\addlinespace[0.3em]
Requests (Python) & Retrieve data from GitHub / PyPI APIs. & Open-source & Automates collection of repository metrics. \\
\addlinespace[0.3em]
Matplotlib / Plotly / Chart.js & Visualization libraries. & Open-source & Create interactive and exportable graphs for dashboards. \\
\addlinespace[0.3em]
AHPy / ahpy & Analytic Hierarchy Process implementation. & Open-source & Automates pairwise comparison scoring. \\
\addlinespace[0.3em]
Flask & Backend web framework. & Open-source & Manages API integration and data handling. \\
\addlinespace[0.3em]
React & Frontend user interface framework. & Open-source & Enables responsive dashboards and visualization. \\
\addlinespace[0.3em]
MySQL / SQLite & Database systems. & Open-source & Store collected data and evaluation results. \\
\bottomrule
\end{tabularx}
\end{table}

Reusing these components ensures consistency, leverages reliability, and minimizes custom development effort.

\subsection{Products That Can Be Copied}

Some open-source or academic research dashboards share functional similarities with the NNL Assessment Tool and may inform design or architecture.

\begin{table}[hp]
\caption{Products That Can Be Copied or Adapted}
\begin{tabularx}{\textwidth}{p{3cm}X X}
\toprule
\textbf{Product} & \textbf{Description} & \textbf{Adaptation Potential} \\
\midrule
Software Assessment Dashboards & Tools that analyze open-source metrics. & Their structure can guide data collection and dashboard design. \\
\addlinespace[0.3em]
University Research Repositories & Academic dashboards for research analytics. & Useful for UI and data categorization strategies. \\
\bottomrule
\end{tabularx}
\end{table}

Adaptation saves design time and provides validated frameworks for implementation while maintaining legal compliance.

\textbf{Considerations:}
\begin{itemize}
    \item Licensing for third-party libraries must be reviewed before adoption.
    \item Integration testing is required to confirm compatibility.
    \item Long-term maintenance and documentation quality will influence selection.
\end{itemize}

Each reused or adapted product will be documented with:
\begin{itemize}
    \item Name and source
    \item Functionality
    \item Integration plan
    \item Licensing details
    \item Selection status
\end{itemize}


\section{New Problems}

This section identifies potential conflicts, risks, or issues that may arise as a result of implementing the NNL Assessment Tool within McMaster University’s research environment. The purpose is to anticipate and document any negative effects or dependencies introduced by the new system.

\subsection{Effects on the Current Environment}

The new tool will operate within McMaster University’s research infrastructure and will rely on institutional hosting (e.g., internal servers). It may introduce additional server load and require IT resources for maintenance.

\textbf{Motivation:} To ensure the new tool integrates smoothly without disrupting existing research tools, storage systems, or academic workflows.

\textbf{Examples:}
\begin{itemize}
    \item Increased data storage requirements may conflict with current quotas.
    \item Additional IT workload for managing hosting or user accounts.
\end{itemize}

\textbf{Considerations:}
\begin{itemize}
    \item Coordination with the IT infrastructure team is required to confirm compatibility with university servers.
    \item Ensure the tool does not negatively affect access to existing research applications or networks.
\end{itemize}

\textbf{Form:} Documented assessment of integration impact with existing systems, supported by infrastructure review.

\subsection{Effects on the Installed Systems}

The new tool will interface with existing systems such as Excel, university authentication systems (SSO), and potentially university-hosted databases.

\textbf{Motivation:} Identify dependencies between the tool and existing platforms, ensuring stable coexistence and avoiding version conflicts.

\textbf{Considerations:}
\begin{itemize}
    \item Compatibility with current Microsoft Excel versions.
    \item Security compliance when connecting to McMaster’s SSO.
    \item Avoid introducing vulnerabilities or version mismatches.
\end{itemize}

\textbf{Form:} Integration map specifying systems affected, their current versions, and compatibility requirements.

\subsection{Potential User Problems}

Potential user challenges include onboarding, usability learning curves, and confusion regarding data visualization or interpretation.

\textbf{Motivation:} Ensure researchers and users can adopt the system efficiently without frustration or misinterpretation of outputs.

\textbf{Considerations:}
\begin{itemize}
    \item Provide user documentation and tutorials.
    \item Offer training sessions or quick-start guides.
    \item Establish a support contact for reporting issues.
\end{itemize}

\subsection{Limitations in the Anticipated Implementation Environment That May Inhibit the New Product}

Possible constraints include limited hosting capacity, restricted access to certain cloud features, and dependence on McMaster’s infrastructure approval.

\textbf{Motivation:} Identify environmental limitations that could delay deployment or reduce tool performance.

\textbf{Examples:}
\begin{itemize}
    \item Hosting quotas may limit database scaling.
    \item University IT policies may restrict certain libraries or APIs.
    \item Limited access to high-performance computing resources.
\end{itemize}

\textbf{Considerations:} Execute a full review to confirm infrastructure readiness.

\subsection{Follow-Up Problems}

Potential long-term issues include sustaining the tool after project completion and keeping data updated as new Neural Network Libraries emerge.

\textbf{Motivation:} Ensure the system remains relevant and operational beyond the capstone timeline.

\textbf{Considerations:}
\begin{itemize}
    \item Define ownership and maintenance responsibilities after project handover.
    \item Plan for version updates, new library integrations, and user feedback loops.
    \item Ensure continuity when original developers graduate.
\end{itemize}


\section{Tasks}

\subsection{Project Planning}

The Neural Network Libraries (NNL) Assessment Tool will be delivered using a hybrid development approach that combines Agile iterations with structured milestone-based deliverables aligned with the McMaster Software Capstone schedule.

The lifecycle is divided into major phases: Requirements, Design, Implementation, Testing, and Deployment, each building toward a functional and hosted tool that supports the research team in evaluating neural network libraries.

This approach ensures iterative feedback from supervisors and domain experts after each milestone, enabling continuous refinement. Development will be managed through GitHub for version control, VS Code for coding, and LaTeX for documentation.

The tool will be hosted on McMaster’s internal infrastructure or an approved equivalent, with key non-functional activities such as user onboarding, data migration, and training planned in the later stages.

\begin{table}[h!]
\centering
\caption{Project Planning Phases}
\begin{tabularx}{\textwidth}{lXlX}
\toprule
\textbf{Phase} & \textbf{Description} & \textbf{Key Activities} & \textbf{Deliverables} \\
\midrule
Initiation & Define problem, scope, and objectives & Document review, team formation, feasibility assessment & Problem Statement, POC Plan, Development Plan \\
Requirements & Gather and formalize system requirements & Stakeholder interviews, drafting of SRS and Hazard Analysis & SRS Document, Hazard Analysis \\
Design & Establish system architecture and interfaces & UI mockups, data flow diagrams, schema design & Design Document \\
Implementation & Build core tool functionality & Develop modules, integrate APIs, implement Excel import/export & Proof of Concept Demo \\
Validation \& Verification & Test and evaluate system performance & Unit and integration testing, review sessions, issue resolution & V\&V Plan, V\&V Report \\
Deployment & Deliver hosted solution & Deploy tool, prepare documentation, conduct final demo & Final Hosted Tool, Presentation, Final Report \\
\bottomrule
\end{tabularx}
\end{table}

\subsection{Planning of the Development Phases}

Each phase contributes to the development of a usable and reliable product. Feedback loops will be incorporated at each stage to ensure alignment with stakeholder expectations, compliance with requirements, and delivery of a secure, maintainable, and user-friendly system.

\begin{table}[h!]
\centering
\caption{Development Phase Plan}
\begin{tabularx}{\textwidth}{lXlXlX}
\toprule
\textbf{Phase Name} & \textbf{Benefit to User} & \textbf{Operational Date} & \textbf{Operating Components} & \textbf{Functional Requirements} & \textbf{Non-Functional Requirements} \\
\midrule
Requirements \& Analysis & Clarifies system objectives and constraints & Week 1–6 & GitHub, LaTeX & Requirements documentation & Accuracy, clarity \\
Design & Defines architecture and interfaces & Week 10–16 & UML tools, wireframing software & UI and backend design & Maintainability \\
Implementation & Delivers core product functionality & Week 16–19 & IDE, databases, APIs & Tool modules, automation scripts & Reliability, usability \\
Testing \& Validation & Ensures product meets all criteria & Week 17–22 & Test suites, CI/CD & Verification of features & Performance \\
Deployment & Provides accessible hosted tool & Week 22–26 & Hosting platform, documentation & Hosted application & Security, accessibility \\
\bottomrule
\end{tabularx}
\end{table}


%\section{Migration to the New Product}
%\subsection{Requirements for Migration to the New Product}
%\lips
%\subsection{Data That Has to be Modified or Translated for the New System}
%\lips

\section{Costs}
There is no development cost for this project, due to the nature of this being a capstone project. 
\\
The costs of hosting the required services, such as the database and the web application will depend on McMaster University's existing infrastructure.
\\
However, estimating using a common cloud provider such as Amazon Web Services (AWS). \\
Using the Relational Database Service (RDS) for database and the Elastic Cloud Computing (EC2) service for hosting.
Assuming around a maximum usage of 20 Hours/Month, the total cost of hosting is 11.63 CAD per month, as shown in Table~\ref{tab:price_table}.
\begin{table}[h!]
\centering
\begin{tabularx}{\textwidth}{@{} X X X c @{}}
\toprule
\textbf{Name} & \textbf{Configuration} & \textbf{Estimated Usage} & \textbf{Total Cost} \\
\midrule
RDS for MySQL & Two vCPU and 8GB of Memory & 20 Hours/Month & 9.76 CAD/Month \\ 
EC2 & t4g.large Instance & 20 Hours/Month & 1.87 USD/Month \\
\bottomrule
\end{tabularx}
\caption{Price estimates and total costs for two AWS services.}
\label{tab:price_table}
\end{table}

\section{User Documentation and Training}
\subsection{User Documentation Requirements}
\subsubsection{User Manual}
The user manual will highlight the key features of the product, and provide additional details for installing, setup and usage that wasn't previously covered in the project's \href{https://github.com/thaafei/DomainX/blob/main/README.md}{README}. \\
\\The maintenance of this document will be the responsibility of the development team. Changes to the product's features, such as adding new features or altering existing features must be reflected in the user manual upon release of the update.

\subsubsection{Release Manual}
The release manual will cover the release process required for future releases of the product, found in the \href{https://github.com/thaafei/DomainX/blob/main/docs/DevelopmentPlan/DevelopmentPlan.pdf}{Development Plan}. It should include the whole CI/CD lifecycle, including team standards, release labelling, and more.\\
\\The maintenance of this document will be the responsibility of the development team. Changes to the CI/CD process, either from the development team or the broader McMaster University infrastructure team should be reflected before the next release.

\subsection{Training Requirements}
\textbf{1. Users should be able to use the tool and utilize key features immediately after following the tutorial} \\ \\
\textbf{2. Users should be able to find key features without consulting additional documentation 95\% of the time.} \\ \\
The responsibilty of the training will first fall towards the development team of the tool. They must ensure the provided in-tool tutorial is up-to-date and sufficient to help a user understand all key features.
\\ Additional training will be provided to the supervisor, hosted by the development team.
Subsequent training will be the responsibility of the supervisor, if needed to train future users of the tool, in the format that the supervisor chooses.
\section{Waiting Room}
\textbf{1. Comparing across Domains}\\
The user should be able to compare two (or more) completed domain analysis against each other. \\\\
\textbf{2. Versioning of Domains}\\
Users can revist and update completed domains, adding new data or editing existing ones. Allowing users to view the evolution of the state of best practice for the domain.

\section{Ideas for Solution}
The following is the development team's idea for the user interface of the tool. Figure~\ref{fig:domainx_ui} shows the initial concept, drawing inspiration from \href{https://octave-online.net/}{Octave Online}, the cloud IDE for Matlab.
\\ The main section of the tool will be where the data is displayed and gathered for each domain. With the sections that can be automatically gathered differentiated using a different colour, such as the gray shown in Figure~\ref{fig:domainx_ui}.
\\ The left sidebar will contain all the domains, with indications on whether it's completed or not. As well as providing a filter to quickly search for a specific domain.
\begin{figure}
\centering
  \includegraphics[totalheight=8cm]{images/DomainX-UI.png}
  \caption{DomainX UI, inspired by Octave Online}
  \label{fig:domainx_ui}
\end{figure}
\newpage{}
\section*{Appendix --- Reflection}

\input{../Reflection.tex}

\input{../SRS_Reflection.tex}

\end{document}